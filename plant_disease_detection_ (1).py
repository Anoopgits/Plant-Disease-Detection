# -*- coding: utf-8 -*-
"""Plant Disease Detection .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KCT_KvLLalR7pejg9J8vxCWEPGour3RZ

Load the datset using kaggle api token
"""

!pip install opendatasets

#
import opendatasets as od
dataset_url = 'https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset'
od.download(dataset_url)

# The dataset has already been downloaded and extracted by opendatasets.download()
# You can now access the files directly in the directory '/content/new-plant-diseases-dataset'

import os

# List the directories within the downloaded dataset path
dataset_path = '/content/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)'
for dirname, _, filenames in os.walk(dataset_path):
    print(f"Directory: {dirname}")
    # Optionally, print file names in each directory (can be very long for large datasets)
    # for filename in filenames:
    #     print(f"  {filename}")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import cv2
from google.colab.patches import cv2_imshow
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.callbacks import EarlyStopping
from PIL import Image

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define the base path to the dataset
dataset_path = '/content/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)'

# Define paths for training and validation data
train_dir = os.path.join(dataset_path, 'train')
valid_dir = os.path.join(dataset_path, 'valid')

# Define image dimensions and batch size
img_height = 224
img_width = 224
batch_size = 32

# Create ImageDataGenerators for training and validation
# Rescale the images by 1/255 and apply some augmentation to the training data
train_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

valid_datagen = ImageDataGenerator(rescale=1./255)

# Load images from directories using flow_from_directory
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical' # Use 'categorical' for multi-class classification
)

valid_generator = valid_datagen.flow_from_directory(
    valid_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical'
)

print("Image data generators created.")
print(f"Number of training samples: {train_generator.n}")
print(f"Number of validation samples: {valid_generator.n}")
print(f"Number of classes: {train_generator.num_classes}")
print(f"Class indices: {train_generator.class_indices}")

"""this datset has 38 class

Number of training samples: 70295

Number of validation samples: 17572

 train=Found 70295 images belonging to 38 classes.

 valid generatior=Found 17572 images belonging to 38 classes.

 and dataset has 3 channel means image are color image

  class indices name:

  Class indices: {'Apple___Apple_scab': 0, 'Apple___Black_rot': 1, 'Apple___Cedar_apple_rust': 2, 'Apple___healthy': 3, 'Blueberry___healthy': 4, 'Cherry_(including_sour)___Powdery_mildew': 5, 'Cherry_(including_sour)___healthy': 6, 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot': 7, 'Corn_(maize)___Common_rust_': 8, 'Corn_(maize)___Northern_Leaf_Blight': 9, 'Corn_(maize)___healthy': 10, 'Grape___Black_rot': 11, 'Grape___Esca_(Black_Measles)': 12, 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)': 13, 'Grape___healthy': 14, 'Orange___Haunglongbing_(Citrus_greening)': 15, 'Peach___Bacterial_spot': 16, 'Peach___healthy': 17, 'Pepper,_bell___Bacterial_spot': 18, 'Pepper,_bell___healthy': 19, 'Potato___Early_blight': 20, 'Potato___Late_blight': 21, 'Potato___healthy': 22, 'Raspberry___healthy': 23, 'Soybean___healthy': 24, 'Squash___Powdery_mildew': 25, 'Strawberry___Leaf_scorch': 26, 'Strawberry___healthy': 27, 'Tomato___Bacterial_spot': 28, 'Tomato___Early_blight': 29, 'Tomato___Late_blight': 30, 'Tomato___Leaf_Mold': 31, 'Tomato___Septoria_leaf_spot': 32, 'Tomato___Spider_mites Two-spotted_spider_mite': 33, 'Tomato___Target_Spot': 34, 'Tomato___Tomato_Yellow_Leaf_Curl_Virus': 35, 'Tomato___Tomato_mosaic_virus': 36, 'Tomato___healthy': 37}
"""

print(train_datagen.samplewise_center)

# Normalize the image

# image dataaugmentatin already handle the normalization

"""now the load and create the object of pretraind model and perform transfer laearning using fine tuning method

VGGnet=>VGGNet pre-trained models, specifically VGG16 and VGG19, are widely used in computer vision for tasks like image classification and feature extraction. These models were developed by the Visual Geometry Group (VGG) at Oxford University and achieved remarkable results in the ImageNet Challenge

Here's a breakdown of the VGG-16 architecture based on the provided details:

1. Input Layer:
Input dimensions: (224, 224, 3)
2. Convolutional Layers (64 filters, 3x3 filters, same padding):
Two consecutive convolutional layers with 64 filters each and a filter size of 3x3.
Same padding is applied to maintain spatial dimensions.
3. Max Pooling Layer (2x2, stride 2):
Max-pooling layer with a pool size of 2x2 and a stride of 2.
4. Convolutional Layers (128 filters, 3x3 filters, same padding):
Two consecutive convolutional layers with 128 filters each and a filter size of 3x3.
5. Max Pooling Layer (2x2, stride 2):
Max-pooling layer with a pool size of 2x2 and a stride of 2.
6. Convolutional Layers (256 filters, 3x3 filters, same padding):
Two consecutive convolutional layers with 256 filters each and a filter size of 3x3.
7. Convolutional Layers (512 filters, 3x3 filters, same padding):
Two sets of three consecutive convolutional layers with 512 filters each and a filter size of 3x3.
8. Max Pooling Layer (2x2, stride 2):
Max-pooling layer with a pool size of 2x2 and a stride of 2.
9. Stack of Convolutional Layers and Max Pooling:
Two additional convolutional layers after the previous stack.
Filter size: 3x3.
10. Flattening:
Flatten the output feature map (7x7x512) into a vector of size 25088.
11. Fully Connected Layers:
Three fully connected layers with ReLU activation.
First layer with input size 25088 and output size 4096.
Second layer with input size 4096 and output size 4096.
Third layer with input size 4096 and output size 1000, corresponding to the 1000 classes in the ILSVRC challenge.
Softmax activation is applied to the output of the third fully connected layer for classification.

transfer learning fine tunning method=> After the initial training, you unfreeze some of the top layers of the pre-trained base model. You then retrain the entire model (the unfrozen layers of the base and your new classification layers) on your dataset, but with a very low learning rate.

import
"""

from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model

"""to create a object of this model"""

conv_base=VGG16(weights='imagenet',include_top=False,input_shape=(224,224,3))

conv_base.trainable = True

set_trainable = False

for layer in conv_base.layers:
  if layer.name == 'block5_conv1':
    set_trainable = True
  if set_trainable:
    layer.trainable = True
  else:
    layer.trainable = False

for layer in conv_base.layers:
  print(layer.name,layer.trainable)

"""unfreeze the last layer of resnet convolution layer so last layer part the traing of model"""

conv_base.summary()

"""create my model for training"""

model=Sequential()
# to the resnet convoution layer in my model
model.add(conv_base)
model.add(Flatten())
model.add(Dense(256,activation='relu'))
# model.add(Dropout(0.5))
model.add(Dense(38,activation='softmax'))

model.summary()

model.compile(optimizer=Adam(learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])

callback=EarlyStopping(monitor='val_loss',patience=2,verbose=1)

history=model.fit(train_generator,epochs=8,validation_data=valid_generator,callbacks=[callback])

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')

"""this visualization is clearly show the model is not overfitting"""

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')

y_pred=model.predict(valid_generator)

print(y_pred[0])

"""this output is probability so can convert in interger form"""

predict_label=np.argmax(y_pred[0])
print(predict_label)

"""perform all dataset"""

y_pred_label=[np.argmax(i) for i in y_pred]

print(y_pred_label)

"""plot the cinfusion matrix so ouput realeation is clear"""

conf_mat=confusion_matrix(valid_generator.classes,y_pred_label)

print(conf_mat)

import seaborn as sns
ax = sns.heatmap(conf_mat,annot=True,fmt='d')
ax.set_ylabel('True label')
ax.set_xlabel('Predicted label')



"""# Building the prediction system"""

input_image_path=input("Enter the path of the image to predict")

"""print the image using the imshow function"""

input_image=cv2.imread(input_image_path)
cv2_imshow(input_image)

type(input_image)

input_image.shape

"""this is RGB image"""

def predict_image_class(image_path):
    # Load and preprocess the image
    img = Image.open(image_path).convert('RGB')
    img = img.resize((img_width, img_height)) # img_width and img_height are defined in cell 'b55534d7'
    img_array = np.array(img) / 255.0  # Rescale to [0, 1]
    img_array = np.expand_dims(img_array, axis=0) # Add batch dimension
    # Make the prediction
    predictions = model.predict(img_array) # model is defined in cell 'FVLyv1RFrk6T'
    predicted_class_index = np.argmax(predictions, axis=1)[0]
    class_indices = train_generator.class_indices
    inverted_class_indices = dict((v, k) for k, v in class_indices.items())
    predicted_class_label = inverted_class_indices[predicted_class_index]

    return predicted_class_label

model.save('plant_disease_model.h5')

